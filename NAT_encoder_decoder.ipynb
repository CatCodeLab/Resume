{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CatCodeLab/Resume/blob/master/NAT_encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztdnV_lsH345"
      },
      "source": [
        "# An Encoder–Decoder Network for Neural Machine Translation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A7tQ1KM7IHyl"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -Uqq ipdb\n",
        "# import ipdb\n",
        "\n",
        "# %pdb on"
      ],
      "metadata": {
        "id": "B96zyUiIraVL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tx-CgTrMc8Sm"
      },
      "outputs": [],
      "source": [
        "# define constants\n",
        "MAX_LENGTH = 10\n",
        "max_words = 50\n",
        "\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooPIV9kGcG44",
        "outputId": "3ed02131-8163-49ea-86fb-5bbcf3d37b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# check gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlzssgC5IBeh",
        "outputId": "eafa8570-ce84-4a11-b07a-4f7654e820db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip to ./spa-eng.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2638744/2638744 [00:00<00:00, 3092771.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./spa-eng.zip to ./\n"
          ]
        }
      ],
      "source": [
        "# download data\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "\n",
        "filename = 'spa-eng'\n",
        "to_path = './'\n",
        "download_and_extract_archive(url, to_path)\n",
        "text = Path(\"./spa-eng/spa.txt\").read_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8BmMOXOEOzUA"
      },
      "outputs": [],
      "source": [
        "# prepare the data\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXLuzplCPXEd",
        "outputId": "62d4493b-981e-4878-8dac-8ace0592e31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How boring! => Qué aburrimiento!\n",
            "I love sports. => Adoro el deporte.\n",
            "Would you like to swap jobs? => Te gustaría que intercambiemos los trabajos?\n"
          ]
        }
      ],
      "source": [
        "# example data\n",
        "for i in range(3):\n",
        "    print(sentences_en[i], \"=>\", sentences_es[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUBOJgs_A7Cf",
        "outputId": "3b44afe8-10f8-46db-ff12-03ec6027c21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-11 04:23:44.514352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-11 04:23:44.514415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-11 04:23:44.515893: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-11 04:23:45.587113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2024-01-11 04:24:01.747790: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-11 04:24:01.747844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-11 04:24:01.749192: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-11 04:24:02.833437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
            "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
            "Collecting es-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.6.0/es_core_news_sm-3.6.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DsK3lGi_hrUu"
      },
      "outputs": [],
      "source": [
        "# option 1: load tokenizer\n",
        "# import spacy\n",
        "# es_tokenizer = spacy.load(\"es_core_news_sm\")\n",
        "# en_tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# option 2\n",
        "es_tokenizer = get_tokenizer('spacy', language='es_core_news_sm')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3Ran_QrHcHKU"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(tokenizer, sentences):\n",
        "        for s in sentences:\n",
        "            yield tokenizer(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NQnjbw2bIhJc"
      },
      "outputs": [],
      "source": [
        "en_vocab = build_vocab_from_iterator(build_vocabulary(en_tokenizer, sentences_en), min_freq=1, specials=['<UNK>', '<PAD>', '<SOS>', '<EOS>'])\n",
        "en_vocab.set_default_index(en_vocab[\"<UNK>\"])\n",
        "\n",
        "es_vocab = build_vocab_from_iterator(build_vocabulary(es_tokenizer, sentences_es), min_freq=1, specials=['<UNK>', '<PAD>', '<SOS>', '<EOS>'])\n",
        "es_vocab.set_default_index(es_vocab[\"<UNK>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-YA4CsVfUzp",
        "outputId": "e6ad1a60-ee87-445d-d27e-11b47ae5dadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{index of(['here', 'is', 'an', 'example'])} -> [69, 12, 79, 1869]\n",
            "{index of(['Qué', 'aburrimiento'])} -> [49, 5500]\n"
          ]
        }
      ],
      "source": [
        "# Test English vocab\n",
        "print(f\"{{index of(['here', 'is', 'an', 'example'])}} -> {en_vocab(['here', 'is', 'an', 'example'])}\")\n",
        "\n",
        "# Test Spanish vocab\n",
        "print(f\"{{index of(['Qué', 'aburrimiento'])}} -> {es_vocab(['Qué', 'aburrimiento'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k43rG8PHKbF5"
      },
      "outputs": [],
      "source": [
        "def prepare_data(inp_sents, target_sents, inp_vocab, target_vocab, inp_tokenizer, target_tokenizer):\n",
        "  data = []\n",
        "  for raw_inp, raw_target in zip(inp_sents, target_sents):\n",
        "    inp_tensor_ = torch.tensor([inp_vocab[token] for token in inp_tokenizer(raw_inp)], dtype=torch.long)\n",
        "    target_tensor_ = torch.tensor([target_vocab[token] for token in target_tokenizer(raw_target)], dtype=torch.long)\n",
        "    data.append((inp_tensor_, target_tensor_))\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEB0Csx3NG4H",
        "outputId": "1201b737-2be4-47da-e62c-0536beb7005c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['How boring!', 'Qué aburrimiento!'], ['I love sports.', 'Adoro el deporte.']]\n"
          ]
        }
      ],
      "source": [
        "print(pairs[:2])\n",
        "\n",
        "train_data = prepare_data(sentences_en[:100_000], sentences_es[:100_000], en_vocab, es_vocab, en_tokenizer, es_tokenizer)\n",
        "val_data = prepare_data(sentences_en[100_000:], sentences_es[100_000:], en_vocab, es_vocab, en_tokenizer, es_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5IifKmW1MFS9"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = en_vocab['<PAD>']\n",
        "SOS_IDX = en_vocab['<SOS>']\n",
        "EOS_IDX = en_vocab['<EOS>']\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  en_batch, es_batch = [], []\n",
        "\n",
        "  for (en_item, es_item) in data_batch:\n",
        "    # en_batch.append(torch.cat([torch.tensor([SOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    # es_batch.append(torch.cat([torch.tensor([SOS_IDX]), es_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    en_batch.append(torch.cat([en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    es_batch.append(torch.cat([es_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "  es_batch = pad_sequence(es_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "\n",
        "  return en_batch.to(device), es_batch.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_loader = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IUG7zUHWddYd"
      },
      "outputs": [],
      "source": [
        "# # build dataset\n",
        "# class SentencesDataset(Dataset):\n",
        "\n",
        "#   def __init__(self, source, target):\n",
        "#     self.source = source\n",
        "#     self.target = target\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.target)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#         source = self.source[idx]\n",
        "#         target = self.target[idx]\n",
        "#         sample = {\"source\": source, \"target\": target}\n",
        "#         return sample\n",
        "\n",
        "# # generate dataset\n",
        "# train_dataset = SentencesDataset(sentences_en[:100_000], sentences_es[:100_000])\n",
        "# test_dataset = SentencesDataset(sentences_en[100_000:], sentences_es[100_000:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KfJMHndEzaPq"
      },
      "outputs": [],
      "source": [
        "# def vectorize_batch(batch):\n",
        "#     en_sen, es_sen = list(zip(*batch))\n",
        "#     X = [en_vocab(en_tokenizer(text)) for text in en_sen]\n",
        "#     X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "#     Y = [es_vocab(es_tokenizer(text)) for text in es_sen]\n",
        "#     Y = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "#     return torch.tensor(X, dtype=torch.int32), torch.tensor(Y) - 1 ## We have deducted 1 from target names to get them in range [0,1,2,3] from [1,2,3,4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q6TMpHuaxgQu"
      },
      "outputs": [],
      "source": [
        "# train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
        "# test_loader  = DataLoader(test_dataset , batch_size=1024, collate_fn=vectorize_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "imp1fqlGf6UR"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# embed_len = 128\n",
        "# hidden_dim = 512\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        # print(f'In encoder: embedding size [{input_size}, {hidden_size}]')\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        # print(f'In encoder: output size [{output.size()}, hidden_size = {hidden.size()}]')\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_MDCANPr59TS"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        # print(f'In decoder: embedding size [{output_size}, {hidden_size}]')\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        # print(f'decoder forward: batch_size {batch_size}, encoder_outputs size = {encoder_outputs.size()}')\n",
        "        # decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(2)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        # print(f'decoder forward: decoder_input {decoder_input.size()}')\n",
        "\n",
        "        # for i in range(MAX_LENGTH):\n",
        "        max_words_length = MAX_LENGTH\n",
        "        if target_tensor is not None:\n",
        "          max_words_length = target_tensor.size(1)\n",
        "\n",
        "        # for i in range(target_tensor.size(1)):\n",
        "        for i in range(max_words_length):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            # print(decoder_output.size())\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                # print(f'we have target_tensor size = {target_tensor.size()}')\n",
        "                # [128, 26])\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "                # print(f'we have decoder_input size = {decoder_input.size()}')\n",
        "                # torch.Size([128, 1])\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                # print(f'decoder_output size = {decoder_output.size()}')\n",
        "                # torch.Size([1, 1, 29103]\n",
        "                # _, topi = decoder_output.topk(1, dim=2)\n",
        "                # If dim is not given, the last dimension of the input is chosen for topk.\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                # print(f'topi.size={topi.size()}')\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "                # print(f'In decoder, decoder_input.size={decoder_input.size()}')\n",
        "\n",
        "        # ipdb.set_trace()\n",
        "        # print(f'decoder_outputs.size={len(decoder_outputs)}')\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        # print(f'Before log_softmax: decoder_outputs.size={decoder_outputs.size()}')\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        # print(f'After log_softmax: decoder_outputs.size={decoder_outputs.size()}')\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        # print(f'forward_step: input_size = {input.size()}')\n",
        "        output = self.embedding(input)\n",
        "        # print(f'forward_step: output_size = {output.size()}')\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GmnfYG-nPfqI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        # print(f'input_tensor size = {input_tensor.size()}, target_tensor size = {target_tensor.size()}')\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        # print(f'encoder_output[{encoder_outputs.size()}], decoder_output[{decoder_outputs.size()}], encoder_output[{target_tensor.size()}] ')\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WK-j2fOsSzRi"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "UBBn-SI-TLRg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "cDK-9Ly-8vsz"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorFromSentence(inp_vocab, inp_tokenizer, sentence):\n",
        "\n",
        "    inp_tensor_ = torch.tensor([inp_vocab[token] for token in inp_tokenizer(sentence)], dtype=torch.long)\n",
        "    # inp_tensor_  = torch.cat([inp_tensor_, torch.tensor([EOS_IDX])], dim=0)\n",
        "\n",
        "    inp_batch = []\n",
        "    inp_batch.append(torch.cat([inp_tensor_, torch.tensor([EOS_IDX])], dim=0))\n",
        "\n",
        "    inp_batch = pad_sequence(inp_batch, padding_value=PAD_IDX, batch_first=True).to(device)\n",
        "    print(f'inp_batch size = {inp_batch.size()}')\n",
        "    return inp_batch\n",
        "\n",
        "    # return torch.tensor(concat_tensor.clone().detach(), dtype=torch.long, device=device).view(1, -1)"
      ],
      "metadata": {
        "id": "_-ugmwa_LfIn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, inp_vocab, inp_tokenizer):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(inp_vocab, inp_tokenizer, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        print(f'encoder_outputs.size = {encoder_outputs.size()}, encoder_hidden.size={encoder_hidden.size()}')\n",
        "        decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        print(f'after decoder: {decoder_outputs.size()}')\n",
        "        _, topi = decoder_outputs.topk(1, dim=2)\n",
        "        decoded_ids = topi.squeeze().tolist()\n",
        "        print(f'index: {decoded_ids}')\n",
        "\n",
        "        decoded_words = []\n",
        "        decoded_words = es_vocab.lookup_tokens(decoded_ids)\n",
        "        print(f'words: {decoded_words}')\n",
        "        # for idx in decoded_ids:\n",
        "        #     if idx.item() == 2:\n",
        "        #         decoded_words.append('<EOS>')\n",
        "        #         break\n",
        "        #     print(f'{idx}: {decoded_words}, {idx}')\n",
        "        #     # decoded_words.append(es_vocab.lookup_tokens(idx.item()))\n",
        "\n",
        "    return decoded_words"
      ],
      "metadata": {
        "id": "DedUmuaXKcVC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGgF-IvOYrCc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3pQc2d8TZBQ"
      },
      "source": [
        "# Training and Evaluating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sKqTBLEzTffa",
        "outputId": "815c89cb-f29e-4d4c-c554-7f65f75e0309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size: 14831\n",
            "Spanish vocab size: 29103\n",
            "0m 44s (- 36m 5s) (1 2%) 2.3012\n",
            "1m 28s (- 35m 35s) (2 4%) 1.6154\n",
            "2m 13s (- 34m 46s) (3 6%) 1.3886\n",
            "2m 57s (- 34m 1s) (4 8%) 1.2339\n",
            "3m 41s (- 33m 15s) (5 10%) 1.1202\n",
            "4m 26s (- 32m 32s) (6 12%) 1.0274\n",
            "5m 10s (- 31m 48s) (7 14%) 0.9502\n",
            "5m 55s (- 31m 4s) (8 16%) 0.8905\n",
            "6m 39s (- 30m 21s) (9 18%) 0.8307\n",
            "7m 24s (- 29m 36s) (10 20%) 0.7868\n",
            "8m 8s (- 28m 51s) (11 22%) 0.7495\n",
            "8m 52s (- 28m 7s) (12 24%) 0.7068\n",
            "9m 37s (- 27m 23s) (13 26%) 0.6755\n",
            "10m 21s (- 26m 39s) (14 28%) 0.6437\n",
            "11m 6s (- 25m 54s) (15 30%) 0.6180\n",
            "11m 51s (- 25m 10s) (16 32%) 0.5918\n",
            "12m 35s (- 24m 27s) (17 34%) 0.5709\n",
            "13m 20s (- 23m 42s) (18 36%) 0.5532\n",
            "14m 5s (- 22m 58s) (19 38%) 0.5322\n",
            "14m 49s (- 22m 14s) (20 40%) 0.5157\n",
            "15m 34s (- 21m 30s) (21 42%) 0.4963\n",
            "16m 19s (- 20m 46s) (22 44%) 0.4855\n",
            "17m 3s (- 20m 2s) (23 46%) 0.4737\n",
            "17m 48s (- 19m 17s) (24 48%) 0.4579\n",
            "18m 33s (- 18m 33s) (25 50%) 0.4474\n",
            "19m 17s (- 17m 48s) (26 52%) 0.4366\n",
            "20m 2s (- 17m 4s) (27 54%) 0.4278\n",
            "20m 47s (- 16m 19s) (28 56%) 0.4161\n",
            "21m 31s (- 15m 35s) (29 57%) 0.4100\n",
            "22m 16s (- 14m 50s) (30 60%) 0.3974\n",
            "23m 0s (- 14m 6s) (31 62%) 0.3909\n",
            "23m 45s (- 13m 21s) (32 64%) 0.3831\n",
            "24m 29s (- 12m 37s) (33 66%) 0.3745\n",
            "25m 14s (- 11m 52s) (34 68%) 0.3691\n",
            "25m 58s (- 11m 8s) (35 70%) 0.3617\n",
            "26m 43s (- 10m 23s) (36 72%) 0.3551\n",
            "27m 28s (- 9m 39s) (37 74%) 0.3493\n",
            "28m 12s (- 8m 54s) (38 76%) 0.3441\n",
            "28m 57s (- 8m 9s) (39 78%) 0.3388\n",
            "29m 41s (- 7m 25s) (40 80%) 0.3320\n",
            "30m 26s (- 6m 40s) (41 82%) 0.3282\n",
            "31m 10s (- 5m 56s) (42 84%) 0.3225\n",
            "31m 55s (- 5m 11s) (43 86%) 0.3158\n",
            "32m 40s (- 4m 27s) (44 88%) 0.3131\n",
            "33m 24s (- 3m 42s) (45 90%) 0.3082\n",
            "34m 9s (- 2m 58s) (46 92%) 0.3043\n",
            "34m 53s (- 2m 13s) (47 94%) 0.3014\n",
            "35m 38s (- 1m 29s) (48 96%) 0.2967\n",
            "36m 23s (- 0m 44s) (49 98%) 0.2917\n",
            "37m 7s (- 0m 0s) (50 100%) 0.2870\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "\n",
        "print(f'English vocab size: {len(en_vocab)}')\n",
        "print(f'Spanish vocab size: {len(es_vocab)}')\n",
        "\n",
        "encoder = EncoderRNN(len(en_vocab), hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, len(es_vocab)).to(device)\n",
        "\n",
        "train(train_loader, encoder, decoder, 50, print_every=1, plot_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=1):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0], en_vocab, en_tokenizer)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "IGoQ2lwn_bxQ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n"
      ],
      "metadata": {
        "id": "KRRJz7wQYqED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d398af-b72c-4872-8ecf-b619aefb0c89"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderRNN(\n",
              "  (embedding): Embedding(29103, 128)\n",
              "  (gru): GRU(128, 128, batch_first=True)\n",
              "  (out): Linear(in_features=128, out_features=29103, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w-K1Ml-MmEH",
        "outputId": "60039496-a711-4b82-bd09-8b442a161343"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> We enjoyed the cool breeze that came from the river.\n",
            "= Disfrutamos de la brisa fresca que provenía del río.\n",
            "inp_batch size = torch.Size([1, 12])\n",
            "encoder_outputs.size = torch.Size([1, 12, 128]), encoder_hidden.size=torch.Size([1, 1, 128])\n",
            "after decoder: torch.Size([1, 10, 29103])\n",
            "index: [5434, 12, 498, 5, 1944, 5, 161, 498, 4, 3]\n",
            "words: ['Disfrutamos', 'el', 'río', 'de', 'pintar', 'de', 'ese', 'río', '.', '<EOS>']\n",
            "< Disfrutamos el río de pintar de ese río . <EOS>\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPULnci398ujAdLr9QPbO54",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}